# A script to calculate emissions changes associated with changes to the fossil
#   fuel load in a region. Depends on objects generated by avertr_setup.R. Test
#   outputs from avertr against outputs from AVERT using avertr_test.R/



# START TIME ######
# For tracking runtime
start_time <- Sys.time()



# SET UP ########
rm(list = ls())

library(tidyverse)
library(readxl)



# USER INPUT ########

# NEEDS WORK
project_capacity <- 500

project_region <- "new-england"

project_type <- "offshore_wind"


# DEFINE/LOAD OBJECTS ######
# Hourly capacity factor; remove the 24 hours corresponding to 2/29
capacity_factor_hourly <- read_excel(
  "./avert-main-module-v4.3.xls",
  sheet = "EERE_Default",
  range = "AJ2:AJ8786"
) |> 
  #slice(c(1:1416, 1441:n())) |> 
  slice(c(1:8760)) |> # NOTE!!! This is the wrong slice, but it's the one AVERT
  #   uses. The above, commented-out slice removes the correct dates.
  #   However, using what AVERT does for now for validation.
  pull(`Offshore Wind`)

# This is simply a vector of each hour of the year 2023
datetime_8760 <- seq(
  from = ymd_hms("2023-01-01 00:00:00"),
  by = "1 hour",
  length.out = 8760
)

# NEI emission factors (cleaned in avertr_setup)
# EVENTUALLY: save 14 versions, only load one
nei_efs <- read_rds("./avertr_setup_output/nei_efs.rds")

# EVENTUALLY: consider only loading in for the specific region
ff_load_bin_data_final <- read_rds("./avertr_setup_output/ff_load_bin_data_final.rds")



# CALC NEW LOAD BINS #######
# Based on the project, find the new ff load bins

# This is the hourly capacity
capacity_hourly_mw <- capacity_factor_hourly * project_capacity_mw

# This is the new hourly net load
new_load_hourly_mw <- bau_load_hourly_mw - capacity_hourly_mw

# This is a vector containing the set of ff load bins for the reion
ff_load_bins_key <- colnames(generation_ff_load_bins) |> 
  as.numeric()

# Remove NAs (note: do this more cleany, it's weird to coerce all names to 
#   numeric and rely on conames being NA, better to just read all as character,
#   filter w/ regexp OR even based on location (bc you knwo which cols you
#   don't want to selec) and then convert to numeric)
ff_load_bins_key <- ff_load_bins_key[!is.na(ff_load_bins_key)]





# NA vector to store the new load bins for the net load of the region.
ff_load_bins_8760_bau <- rep(NA, 8760)

ff_load_bins_8760_bau_next <- rep(NA, 8760)

# Calculate the new load bin
for (i in 1:length(bau_load_hourly_mw)) {
  diff <- bau_load_hourly_mw[i] - ff_load_bins_key
  diff[diff < 0] <- NA # Bc of AVERT search alg, only grabs load bins BELOW the hourly load; here, diff is negative iff the given ff load bin is greater than hourly generation, but those cases are not considered matches in AVERT
  current_load_bin_index <- which.min(diff)
  ff_load_bins_8760_bau[i] <- ff_load_bins_key[current_load_bin_index]
  ff_load_bins_8760_bau_next[i] <- ff_load_bins_key[current_load_bin_index + 1] # EVENTUALLY: The better way to do this is to make an 8760x2 matrix "next load bin library". The first col is ff_load_bins_key, the second is the first, shifted by 1. Then you just save to an array or something....although idk does really help runtime? The join is the issue...
}


# NA vector to store the new load bins for the net load of the region.
ff_load_bins_8760 <- rep(NA, 8760)

ff_load_bins_8760_next <- rep(NA, 8760)

# Calculate the new load bin
for (i in 1:length(new_load_hourly_mw)) {
  diff <- new_load_hourly_mw[i] - ff_load_bins_key
  diff[diff < 0] <- NA
  current_load_bin_index <- which.min(diff)
  ff_load_bins_8760[i] <- ff_load_bins_key[current_load_bin_index]
  ff_load_bins_8760_next[i] <- ff_load_bins_key[current_load_bin_index + 1]
}


# ASSIGN VALUES ##########
# We now have the 8760 for net load bin in each hour, after our new project.
#   But we still need to, for each hour, based on the load bin, get the
#   information on generation and pollutants. E.g., we know that net load was
#   in the 2000 MW bin in hour 2293 in the region, but we don't know what generation, 
#   so2 emissions, nox emissions, etc. each EGU has in the 2000 MW bin.

# After reading functional programming section of advanced R, clean this up
# Function takes a read-in df containing information about each EGU's activity
#   at each load bin, and tidies it
# AND RENAME this function








# 4/12, 4pm: Joey. Here are the next steps.
# First, in order to get the function below working with only a single join,
#   you should simply remove colnm argument from it so that you can determinately
#   pick out the column in order to lead() it, to get the next value. (Additionally,
#   it might be worth putting a check on that col somewhere in the code
#   to make sure it's in ascending order. It def is, but still.) Then use a
#   map() later to rename it. After all that, you can remove the second join()
#   in the loop. Oh, and change that loop to a purrr functional, like walk() at least.
# Second, AND YOU MAY WANT TO DO THIS FIRST: it's time to start re-arragning
#   and documenting. I think it makes sense to have a sheet where you load
#   a bunch of standard objects for the different scenarios and save them as
#   r data files. I'd do that now. Namely, you'll want like a list for
#   each region, maybe other info idk. Start doing that now, and then put it
#   into one script later. You should also move that concern abt the day being
#   off into another section of the script.
























eval(iris)

as.character(iris)



join_data <- function(x_ff_load_bins, colnm) {
  colnm_sym <- sym(colnm)
  x_ff_load_bins <- x_ff_load_bins |> 
    pivot_longer(
      any_of(as.character(ff_load_bins_key)),
      names_to = "ff_load_bins_8760",
      values_to = colnm) |> 
    mutate(
      ff_load_bins_8760 = as.numeric(ff_load_bins_8760)
      # nextnum = lead(!!colnm_sym),
      # nextnum = case_when( # When the load bin is as high as it can go, there's no "next" load bin. lead() pulls in the lowest load bin, but it shouldn't
      #   ff_load_bins_8760 == max(ff_load_bins_key) ~ NA,
      #   TRUE ~ nextnum
      #)
    )
  return(x_ff_load_bins) # This returns a df which has a row for each unit for each load bin.
}

# Get all the EGU names
EGU_names_key <- generation_ff_load_bins |> 
  pull(`Full Unit Name`)

# In each df, select only relevant cols
ff_load_bins_list <- ff_load_bins_list |> 
  map(~select(., !(State:`Unit Code`)))

# Apply the above tidying function
ff_load_bins_list <- ff_load_bins_list |> 
  map2(names(ff_load_bins_list), ~join_data(.x, .y))


## BAU Scenario =========
# This is the information for the BAU scenario â€” the one where there's no load
#   difference

# Take Cartesian product of ff_load_bins and EGU names. So we end up with
#    a row for each EGU name-load bin pair
test_bau <- expand.grid(
  ff_load_bins_8760_bau = ff_load_bins_8760_bau, # Change this ot have a name analogous to ff_load_bins, etc. OR maybe just don't change name at all?
  `Full Unit Name` = EGU_names_key
) |> 
  as_tibble() |> 
  add_column(datetime = rep(datetime_8760, length(EGU_names_key)),
             ff_load_bins_8760_bau_next = rep(ff_load_bins_8760_bau_next, length(EGU_names_key)),
             bau_load_hourly_mw = rep(bau_load_hourly_mw, length(EGU_names_key)))



# Eventually: might be best to save the ff load bin index directly, rather than
#   calculate load bin so early on
# Use the load bin col and the ff_load_bins_key to find the next load bin.
# Do the join twice: once for the current load bin, and once for the next
#   load bin. (What if you're in the max load bin? Shouldn't happen. You only get
#   into a load bin if true load is above it, and if true load is above the max
#   load bin, it shouldn't run.)
# Take the difference in the two values across the load bins, divide by the difference
#   in the two load bins. That's slope.
# Backfit for intercept
#   Calculate value.

# FOR NOW you're not worry abt cases where you have a load bin as max load, but
#   eventually you need to add that functionality, since someone could run a 
#   scenario like that.

# This is the biggest slowdown w the current algo: you join twice, even though
#   after the first join you can easily determine what the second join should be,
#   simply based on the matrix location of the values. Maybe best way is to only
#   load in index values in the above for loop, and then just literally index each
#   table in the ff_load_bins_list?
for (i in 1:length(ff_load_bins_list)) {
  test_bau <- test_bau |> 
    left_join(ff_load_bins_list[[i]], by = join_by(ff_load_bins_8760_bau == ff_load_bins_8760, `Full Unit Name`)) |> 
    left_join(ff_load_bins_list[[i]], by = join_by(ff_load_bins_8760_bau_next == ff_load_bins_8760, `Full Unit Name`))
}



# Rename columns
test_bau <- test_bau |>
  rename_with(
    .fn = ~str_remove(., "_ff_load_bins"),
    .cols = !c(ff_load_bins_8760_bau:`Full Unit Name`)
  )



## Alt Scenario =========
# Take Cartesian product of ff_load_bins and EGU names. So we end up with
#    a row for each EGU name-load bin pair
test <- expand.grid(
  ff_load_bins_8760 = ff_load_bins_8760,
  `Full Unit Name` = EGU_names_key
) |> 
  as_tibble() |> 
  add_column(datetime = rep(datetime_8760, length(EGU_names_key)),
             ff_load_bins_8760_next = rep(ff_load_bins_8760_next, length(EGU_names_key)),
             new_load_hourly_mw = rep(new_load_hourly_mw, length(EGU_names_key)))






# join on relevant values
for (i in 1:length(ff_load_bins_list)) {
  test <- test |> 
    left_join(ff_load_bins_list[[i]], by = join_by(ff_load_bins_8760, `Full Unit Name`)) |> 
    left_join(ff_load_bins_list[[i]], by = join_by(ff_load_bins_8760_next == ff_load_bins_8760, `Full Unit Name`))
}





# Rename columns
test <- test |>
  rename_with(
    .fn = ~str_remove(., "_ff_load_bins"),
    .cols = !c(ff_load_bins_8760:`Full Unit Name`)
  )

# OZONE SEASON SPLIT #############
# Split up into ozone season and not. As per AVERT documentation, ozone season is
#   May to September inclusive.
test_ozone <- test |>
  filter(between(datetime, ymd_hms("2012-05-01 00:00:00"), ymd_hms("2012-09-30 23:00:00")))

test_non <- test |>
  anti_join(test_ozone, by = join_by(datetime))

# # Check:
# nrow(test_ozone) + nrow(test_non) == nrow(test)
# intersect(test_ozone$datetime, test_non$datetime)

test_ozone <- test_ozone |> 
  select(ff_load_bins_8760:generation.y, contains("ozone")) |> 
  rename_with(~str_replace(., "_ozone", ""))

test_non <- test_non |> 
  select(ff_load_bins_8760:generation.y, !contains("ozone")) |> 
  rename_with(~str_replace(., "_non", ""))

test <- test_ozone |> 
  bind_rows(test_non)

# end.time <- Sys.time()
# time.taken <- end.time - start.time
  








test_bau_ozone <- test_bau |>
  filter(between(datetime, ymd_hms("2012-05-01 00:00:00"), ymd_hms("2012-09-30 23:00:00")))

test_bau_non <- test_bau |>
  anti_join(test_bau_ozone, by = join_by(datetime))

# # Check:
# nrow(test_bau_ozone) + nrow(test_bau_non) == nrow(test_bau)
# intersect(test_bau_ozone$datetime, test_bau_non$datetime)

test_bau_ozone <- test_bau_ozone |> 
  select(ff_load_bins_8760_bau:generation.y, contains("ozone")) |> 
  rename_with(~str_replace(., "_ozone", ""))

test_bau_non <- test_bau_non |> 
  select(ff_load_bins_8760_bau:generation.y, !contains("ozone")) |> 
  rename_with(~str_replace(., "_non", ""))

test_bau <- test_bau_ozone |> 
  bind_rows(test_bau_non)


# INTERPOLATION #########
get_val_bau <- function(current_bin, next_bin) {
  slope <- (current_bin - next_bin) / (test_bau$ff_load_bins_8760_bau - test_bau$ff_load_bins_8760_bau_next)
  intercept <- current_bin - (slope * test_bau$ff_load_bins_8760_bau)
  val <- (test_bau$bau_load_hourly_mw * slope) + intercept
  return(val)
}

current_load_bin_vals_bau <- test_bau |> 
  select(contains(".x")) |> 
  as.list()

next_load_bin_vals_bau <- test_bau |> 
  select(contains(".y")) |> 
  as.list()

res_list_bau <- map2(current_load_bin_vals_bau, next_load_bin_vals_bau, get_val_bau)

res_temp_bau <- res_list_bau |>
  c(select(test_bau, `Full Unit Name`)) |> 
  as_tibble() |> 
  left_join(nei_efs, by = join_by(`Full Unit Name` == `Full Name`))

res_temp_bau <- res_temp_bau |> 
  mutate(pm25.x = PM2.5...36 * heat.x,
         vocs.x = VOCs...37 * heat.x,
         nh3.x = NH3...38 * heat.x)

res_list_bau <- res_temp_bau |> 
  select(!c(`Full Unit Name`, PM2.5...36:NH3...38)) |> 
  as.list()



# CHECK AVERT CODE for how they do this...






get_val <- function(current_bin, next_bin) { # EVENTUALLY: seems best to just have one get_val function, with three additional arguments for the three specific cols, OR you can name the cols the same across test and test_bau, and just pass one additional argument for the df...
  slope <- (current_bin - next_bin) / (test$ff_load_bins_8760 - test$ff_load_bins_8760_next)
  intercept <- current_bin - (slope * test$ff_load_bins_8760)
  val <- (test$new_load_hourly_mw * slope) + intercept
  return(val)
}

current_load_bin_vals <- test |> 
  select(contains(".x")) |> 
  as.list()

next_load_bin_vals <- test |> 
  select(contains(".y")) |> 
  as.list()

res_list <- map2(current_load_bin_vals, next_load_bin_vals, get_val)

res_temp <- res_list |>
  c(select(test, `Full Unit Name`)) |> 
  as_tibble() |> 
  left_join(nei_efs, by = join_by(`Full Unit Name` == `Full Name`))

res_temp <- res_temp |> 
  mutate(pm25.x = PM2.5...36 * heat.x,
         vocs.x = VOCs...37 * heat.x,
         nh3.x = NH3...38 * heat.x)

res_list <- res_temp |> 
  select(!c(`Full Unit Name`, PM2.5...36:NH3...38)) |> 
  as.list()



qt <- read_rds("bau_scenarios_2023.rds")

set.seed(50)
qt[[7]] |> arrange(data_generation, data_so2, data_nox) |> sample_n(100) |> view()

set.seed(50)
res_list_bau |> bind_cols() |> arrange(generation.x, so2.x, nox.x) |> sample_n(100) |> view()

# Eventually: you'll want to split this up into two steps: just find raw
#   differences, then round some to 3, some to 6
changes <- map2(res_list, res_list_bau, function(.x, .y) round(.x - .y, 6))


final_changes <- test |> 
  select(ff_load_bins_8760:new_load_hourly_mw) |> 
  add_column(bind_cols(changes))


tt <- final_changes |> summarize(
  across(generation.x:nh3.x, sum),
  .by = `Full Unit Name`
)






# Later: do a full check to ensure variable names are reasonable in each
#   script, and that they're compatible between scripts





# IDEAS (as of 4/8, 2pm): Looks like they exclude load hours outside of
#   the lowest load bin or highest load bin. (Note: looks like this is
#   checked against the raw load, not  the load binnified version of it)




# Recall that you can open up macros and compile if you need to,
#   add breakpoints, and then hover over variable names to get the values.
#    





# NOTE: you will run up against rare so2 emission events plants (altho
#   not in New England)



